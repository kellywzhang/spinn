{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_size = 50\n",
    "embedding_dim = 30\n",
    "batch_size = 3\n",
    "sequence_length = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 44  23  25  11  21\n",
       "  8  14  42  10   0\n",
       " 28  28  35   0   0\n",
       "[torch.LongTensor of size 3x5]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_input = np.random.randint(low=0, high=vocab_size, size=(batch_size, sequence_length))\n",
    "np_input[1][-1] = 0\n",
    "np_input[2][-1] = 0\n",
    "np_input[2][-2] = 0\n",
    "\n",
    "inputs = Variable(torch.from_numpy(np_input))\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 124\n",
       "  74\n",
       "  91\n",
       "[torch.LongTensor of size 3x1]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(inputs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 5, 30])\n",
      "Variable containing:\n",
      " 1  1  1  1  1\n",
      " 1  1  1  1  0\n",
      " 1  1  1  0  0\n",
      "[torch.FloatTensor of size 3x5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "B = embedding(inputs)\n",
    "print(B.size())\n",
    "s_b = torch.gt(inputs, 0).float()\n",
    "print(s_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 30])\n",
      "[Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.FloatTensor of size 3x1]\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "V = [Variable(torch.zeros(batch_size, embedding_dim))]\n",
    "print(V[0].size())\n",
    "s = [Variable(torch.zeros(batch_size, 1))]\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 5, 30])\n",
      "Variable containing:\n",
      " 1  1  1  1  1\n",
      " 1  1  1  1  0\n",
      " 1  1  1  0  0\n",
      "[torch.FloatTensor of size 3x5]\n",
      "\n",
      "Variable containing:\n",
      " 0.5315\n",
      " 0.8538\n",
      " 0.7823\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "0\n",
      "Variable containing:\n",
      " 0.5315\n",
      " 0.8538\n",
      " 0.7823\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      " 0.4685  1.0000  1.0000  1.0000  1.0000\n",
      " 0.1462  1.0000  1.0000  1.0000  0.0000\n",
      " 0.2177  1.0000  1.0000  0.0000  0.0000\n",
      "[torch.FloatTensor of size 3x5]\n",
      "\n",
      "0\n",
      "Variable containing:\n",
      " 0.4685\n",
      " 0.1462\n",
      " 0.2177\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "1\n",
      "Variable containing:\n",
      " 0.0630\n",
      " 0.7075\n",
      " 0.5646\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      " 0.0000  0.9370  1.0000  1.0000  1.0000\n",
      " 0.0000  0.2925  1.0000  1.0000  0.0000\n",
      " 0.0000  0.4354  1.0000  0.0000  0.0000\n",
      "[torch.FloatTensor of size 3x5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "B = embedding(inputs)\n",
    "print(B.size())\n",
    "s_b = torch.gt(inputs, 0).float()\n",
    "print(s_b)\n",
    "\n",
    "def readBuffer(alpha, B, s_b, pop=False):\n",
    "    batch_size = B.size(0)\n",
    "    sequence_len = B.size(1)\n",
    "    embedding_dim = B.size(2)\n",
    "    \n",
    "    cumsum = Variable(torch.zeros(batch_size).float())\n",
    "    vector = Variable(torch.zeros(batch_size, embedding_dim).float())\n",
    "    batch_zeros = Variable(torch.zeros(batch_size))\n",
    "    \n",
    "    # May be more efficient not to loop like this... especially when buffer is empty\n",
    "    for i in range(sequence_len):\n",
    "        \n",
    "        weights = torch.min(s_b[:, i], torch.max(batch_zeros, alpha - cumsum))  \n",
    "        vector = torch.add(vector, torch.mul(weights.unsqueeze(1).expand_as(B[:, i]), B[:, i]))\n",
    "        cumsum = torch.add(cumsum, weights)\n",
    "        if pop:\n",
    "            s_b[:, i] = torch.add(s_b[:, i], torch.mul(weights, -1))\n",
    "            \n",
    "            \n",
    "        print(i)\n",
    "        print(weights)\n",
    "        \n",
    "        if batch_size <= torch.sum(torch.ge(cumsum, alpha)).data[0]:\n",
    "            break\n",
    "            \n",
    "    return vector, s_b\n",
    "\n",
    "alpha_shift = Variable(torch.rand(batch_size))\n",
    "print(alpha_shift)\n",
    "vector, s_b = readBuffer(alpha_shift, B, s_b, pop=True)\n",
    "print(s_b)\n",
    "vector, s_b = readBuffer(alpha_shift, B, s_b, pop=True)\n",
    "print(s_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pushStack(vector, alpha, V, s):\n",
    "    V = [vector] + V\n",
    "    s = [alpha] + s\n",
    "    \n",
    "    return V, s\n",
    "    \n",
    "V, s = pushStack(Variable(torch.ones(batch_size, embedding_dim)), Variable(torch.FloatTensor(batch_size).fill_(1)), V, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Variable containing:\n",
      " 0.0902\n",
      " 0.0367\n",
      " 0.2763\n",
      "[torch.FloatTensor of size 3]\n",
      ", Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.FloatTensor of size 3]\n",
      ", Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.FloatTensor of size 3]\n",
      ", Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.FloatTensor of size 3]\n",
      ", Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.FloatTensor of size 3]\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Variable containing:\n",
       "  0\n",
       "  0\n",
       "  0\n",
       " [torch.FloatTensor of size 3], Variable containing:\n",
       "  0\n",
       "  0\n",
       "  0\n",
       " [torch.FloatTensor of size 3], Variable containing:\n",
       "  0.0902\n",
       "  0.0367\n",
       "  0.2763\n",
       " [torch.FloatTensor of size 3], Variable containing:\n",
       "  1\n",
       "  1\n",
       "  1\n",
       " [torch.FloatTensor of size 3], Variable containing:\n",
       "  0\n",
       "  0\n",
       "  0\n",
       " [torch.FloatTensor of size 3]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V = [Variable(torch.zeros(batch_size, embedding_dim))]\n",
    "s = [Variable(torch.zeros(batch_size))]\n",
    "alpha_push = Variable(torch.rand(batch_size))\n",
    "# print(alpha_push)\n",
    "alpha_ones = Variable(torch.ones(batch_size))\n",
    "V, s = pushStack(Variable(torch.rand(batch_size, embedding_dim)), alpha_ones, V, s)\n",
    "V, s = pushStack(Variable(torch.rand(batch_size, embedding_dim)), alpha_ones, V, s)\n",
    "V, s = pushStack(Variable(torch.rand(batch_size, embedding_dim)), alpha_ones, V, s)\n",
    "V, s = pushStack(Variable(torch.rand(batch_size, embedding_dim)), alpha_push, V, s)\n",
    "# print(s)\n",
    "\n",
    "def readStack(alpha, V, s, pop=False):\n",
    "    batch_size = V[0].size(0)\n",
    "    embedding_dim = V[0].size(1)\n",
    "    \n",
    "    vector1 = Variable(torch.zeros(batch_size, embedding_dim).float())\n",
    "    vector2 = Variable(torch.zeros(batch_size, embedding_dim).float())\n",
    "    \n",
    "    cumsum = Variable(torch.zeros(batch_size).float())\n",
    "    batch_zeros = Variable(torch.zeros(batch_size))\n",
    "    batch_ones = Variable(torch.ones(batch_size))\n",
    "    batch_alpha = Variable(torch.ones(batch_size)) if alpha is None else alpha\n",
    "    \n",
    "    # May be more efficient not to loop like this... especially when stack is empty\n",
    "    for i in range(len(V)):\n",
    "        weights1 = torch.min(s[i], torch.max(batch_zeros, batch_alpha - cumsum))\n",
    "        weights2 = torch.min(s[i], torch.max(batch_zeros, batch_ones + batch_alpha - cumsum)) - weights1\n",
    "        cumsum = torch.add(cumsum, weights1+weights2)\n",
    "        \n",
    "        vector1 = torch.add(vector1, torch.mul(weights1.unsqueeze(1).expand_as(V[0]), V[i]))\n",
    "        vector2 = torch.add(vector2, torch.mul(weights2.unsqueeze(1).expand_as(V[0]), V[i]))\n",
    "        \n",
    "        if pop:\n",
    "            s[i] = torch.add(s[i], torch.mul(weights1+weights2, -1))\n",
    "        \n",
    "        if batch_size == torch.sum(torch.ge(cumsum, 2)).data[0]:\n",
    "            break\n",
    "\n",
    "    return s\n",
    "\n",
    "# print(\"s\", s)\n",
    "# alpha_reduce = Variable(torch.ones(batch_size))\n",
    "r = readStack(None, V, s, pop=False)\n",
    "print(r)\n",
    "readStack(None, V, s, pop=True)\n",
    "# print(\"s\", s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1.0902\n",
       " 1.0367\n",
       " 1.2763\n",
       "[torch.FloatTensor of size 3x1]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.cat([x.unsqueeze(1) for x in s], 1), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       " \n",
       " Columns 0 to 12 \n",
       "     0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       " \n",
       " Columns 13 to 25 \n",
       "     0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       " \n",
       " Columns 26 to 29 \n",
       "     0     0     0     0\n",
       "     0     0     0     0\n",
       "     0     0     0     0\n",
       " [torch.FloatTensor of size 3x30], Variable containing:\n",
       "  0.0000  1.0000  1.0000  1.0000  1.0000\n",
       "  0.0000  0.8942  1.0000  1.0000  0.0000\n",
       "  0.0000  1.0000  1.0000  0.0000  0.0000\n",
       " [torch.FloatTensor of size 3x5])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pop(alpha, B, s_b):\n",
    "    batch_size = B.size(0)\n",
    "    sequence_len = B.size(1)\n",
    "    embedding_dim = B.size(2)\n",
    "    \n",
    "    cumsum = Variable(torch.zeros(batch_size).float())\n",
    "    read = Variable(torch.zeros(batch_size, embedding_dim).float())\n",
    "    batch_zeros = Variable(torch.zeros(batch_size))\n",
    "    batch_alphas = Variable(torch.ones(batch_size).fill_(alpha))\n",
    "    \n",
    "    # May be more efficient not to loop like this... especially when buffer is empty\n",
    "    for i in range(sequence_len):\n",
    "        weights = torch.min(s_b[:, i], torch.max(batch_zeros, batch_alphas - cumsum))\n",
    "        read = torch.add(read, torch.mul(weights.unsqueeze(1).expand_as(B[:, i]), B[:, i]))\n",
    "        cumsum += s_b[:, i]\n",
    "        s_b[:, i] = torch.add(s_b[:, i], torch.mul(weights, -1))\n",
    "        \n",
    "        if batch_size <= torch.sum(torch.ge(cumsum, alpha)):\n",
    "            break\n",
    "            \n",
    "    return read, s_b\n",
    "\n",
    "pop(1, B, s_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "\n",
      "Columns 0 to 12 \n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "\n",
      "Columns 13 to 25 \n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "\n",
      "Columns 26 to 29 \n",
      "    0     0     0     0\n",
      "    0     0     0     0\n",
      "    0     0     0     0\n",
      "[torch.FloatTensor of size 3x30]\n",
      "\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.FloatTensor of size 3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cumsum = Variable(torch.zeros(batch_size).float())\n",
    "read = Variable(torch.zeros(batch_size, embedding_dim).float())\n",
    "\n",
    "batch_zeros = Variable(torch.zeros(batch_size))\n",
    "batch_ones = Variable(torch.ones(batch_size))\n",
    "for i in range(len(s_b[0])):\n",
    "    weights = torch.min(s_b[:, i], torch.max(batch_zeros, 1 - cumsum))    \n",
    "    read = torch.add(read, torch.mul(weights.unsqueeze(1).expand_as(B[:, i]), B[:, i]))\n",
    "    cumsum += s_b[:, i]\n",
    "    if batch_size <= torch.sum(torch.ge(cumsum, 1)):\n",
    "        break\n",
    "    \n",
    "print(read)\n",
    "print(cumsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Peek, Pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "controller = nn.LSTMCell(input_size=embedding_dim*3, hidden_size=embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = nn.Linear(in_features=embedding_dim, out_features=2)\n",
    "\n",
    "F.softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def treelstm(c_left, c_right, gates, use_dropout=False, training=None):\n",
    "    hidden_dim = c_left.size()[1]\n",
    "\n",
    "    assert gates.size()[1] == hidden_dim * 5, \"Need to have 5 gates.\"\n",
    "\n",
    "    def slice_gate(gate_data, i):\n",
    "        return gate_data[:, i * hidden_dim:(i + 1) * hidden_dim]\n",
    "\n",
    "    # Compute and slice gate values\n",
    "    i_gate, fl_gate, fr_gate, o_gate, cell_inp = \\\n",
    "        [slice_gate(gates, i) for i in range(5)]\n",
    "\n",
    "    # Apply nonlinearities\n",
    "    i_gate = F.sigmoid(i_gate)\n",
    "    fl_gate = F.sigmoid(fl_gate)\n",
    "    fr_gate = F.sigmoid(fr_gate)\n",
    "    o_gate = F.sigmoid(o_gate)\n",
    "    cell_inp = F.tanh(cell_inp)\n",
    "\n",
    "    # Compute new cell and hidden value\n",
    "    i_val = i_gate * cell_inp\n",
    "    dropout_rate = 0.1\n",
    "    if use_dropout:\n",
    "        i_val = F.dropout(i_val, dropout_rate, training=training)\n",
    "    c_t = fl_gate * c_left + fr_gate * c_right + i_val\n",
    "    h_t = o_gate * F.tanh(c_t)\n",
    "\n",
    "    return (c_t, h_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 10  34  15  48  48\n",
      " 14  33  17  27   0\n",
      " 47  46  34   0   0\n",
      "[torch.LongTensor of size 3x5]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "\n",
       "Columns 0 to 9 \n",
       "-0.1191  0.2419 -0.2742  0.0171  0.0240  0.1359 -0.1157  0.1221 -0.1110  0.2958\n",
       " 0.0070 -0.0128  0.0006 -0.0003  0.0163  0.0213  0.0085 -0.0048 -0.0063 -0.0138\n",
       "-0.0014 -0.0132  0.0042 -0.0092  0.0117  0.0218  0.0094 -0.0085 -0.0016 -0.0114\n",
       "\n",
       "Columns 10 to 19 \n",
       "-0.2905  0.1654 -0.0387 -0.0140  0.4230  0.0085 -0.0100 -0.1814  0.2243  0.2183\n",
       "-0.0083 -0.0173 -0.0118 -0.0449 -0.0134  0.0237 -0.0354 -0.0014  0.0327  0.0068\n",
       "-0.0030 -0.0184 -0.0126 -0.0435 -0.0081  0.0242 -0.0378  0.0001  0.0313  0.0107\n",
       "\n",
       "Columns 20 to 29 \n",
       " 0.3681 -0.0540  0.2215 -0.0649 -0.2742  0.2598  0.1382 -0.1867 -0.0145 -0.2273\n",
       " 0.0278  0.0274 -0.0227 -0.0240  0.0204  0.0375  0.0269  0.0150  0.0259 -0.0322\n",
       " 0.0277  0.0336 -0.0286 -0.0267  0.0189  0.0393  0.0250  0.0125  0.0283 -0.0362\n",
       "[torch.FloatTensor of size 3x30]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SoftStack(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_size, vocab_size):\n",
    "        super(SoftStack, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vocab_size = vocab_size\n",
    "        \n",
    "        # Reduce function for semantic composition.\n",
    "        self.tree_left = nn.Linear(in_features=hidden_size, out_features=5*hidden_size)\n",
    "        self.tree_right = nn.Linear(in_features=hidden_size, out_features=5*hidden_size)\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.controller = nn.LSTMCell(input_size=hidden_size*3, hidden_size=hidden_size)\n",
    "        self.alpha_projector = nn.Linear(in_features=hidden_size, out_features=2)\n",
    "        \n",
    "    def readBuffer(self, alpha, B, s_b, pop=False):\n",
    "        batch_size = B.size(0)\n",
    "        sequence_len = B.size(1)\n",
    "\n",
    "        cumsum = Variable(torch.zeros(batch_size).float())\n",
    "        vector = Variable(torch.zeros(batch_size, self.embedding_dim).float())\n",
    "        batch_zeros = Variable(torch.zeros(batch_size))\n",
    "        batch_alpha = Variable(torch.ones(batch_size)) if alpha is None else alpha\n",
    "        \n",
    "        # May be more efficient not to loop like this... especially when buffer is empty\n",
    "        for i in range(sequence_len):\n",
    "\n",
    "            weights = torch.min(s_b[:, i], torch.max(batch_zeros, batch_alpha - cumsum))  \n",
    "            vector = torch.add(vector, torch.mul(weights.unsqueeze(1).expand_as(B[:, i]), B[:, i]))\n",
    "            cumsum = torch.add(cumsum, weights)\n",
    "            if pop:\n",
    "                s_b[:, i] = torch.add(s_b[:, i], torch.mul(weights, -1))\n",
    "\n",
    "            if batch_size <= torch.sum(torch.ge(cumsum, batch_alpha)).data[0]:\n",
    "                break\n",
    "\n",
    "        return vector, s_b\n",
    "    \n",
    "    def pushStack(self, vector, alpha, V, s):\n",
    "        V = [vector] + V\n",
    "        s = [alpha] + s\n",
    "\n",
    "        return V, s\n",
    "    \n",
    "    def readStack(self, alpha, V, s, pop=False):\n",
    "        batch_size = V[0].size(0)\n",
    "        embedding_dim = V[0].size(1)\n",
    "    \n",
    "        vector1 = Variable(torch.zeros(batch_size, embedding_dim).float())\n",
    "        vector2 = Variable(torch.zeros(batch_size, embedding_dim).float())\n",
    "\n",
    "        cumsum = Variable(torch.zeros(batch_size).float())\n",
    "        batch_zeros = Variable(torch.zeros(batch_size))\n",
    "        batch_ones = Variable(torch.ones(batch_size))\n",
    "        batch_alpha = Variable(torch.ones(batch_size)) if alpha is None else alpha\n",
    "\n",
    "        # May be more efficient not to loop like this... especially when stack is empty\n",
    "        for i in range(len(V)):\n",
    "            weights1 = torch.min(s[i], torch.max(batch_zeros, batch_alpha - cumsum))\n",
    "            weights2 = torch.min(s[i], torch.max(batch_zeros, batch_ones + batch_alpha - cumsum)) - weights1\n",
    "            cumsum = torch.add(cumsum, weights1+weights2)\n",
    "\n",
    "            vector1 = torch.add(vector1, torch.mul(weights1.unsqueeze(1).expand_as(V[0]), V[i]))\n",
    "            vector2 = torch.add(vector2, torch.mul(weights2.unsqueeze(1).expand_as(V[0]), V[i]))\n",
    "\n",
    "            if pop:\n",
    "                s[i] = torch.add(s[i], torch.mul(weights1+weights2, -1))\n",
    "\n",
    "            if batch_size == torch.sum(torch.ge(cumsum, 2)).data[0]:\n",
    "                break\n",
    "\n",
    "        return vector1, vector2, s\n",
    "    \n",
    "    def init_controller(self, batch_size):\n",
    "        # h_t, c_t\n",
    "        state = (Variable(torch.zeros(batch_size, self.hidden_size)), \\\n",
    "                Variable(torch.zeros(batch_size, self.hidden_size)))\n",
    "        return state\n",
    "    \n",
    "    def run_tree(self, v1, v2, use_dropout=False):\n",
    "        gates = self.tree_left(v1)\n",
    "        gates += self.tree_right(v2)\n",
    "        c_t, h_t = treelstm(c_left=v1, c_right=v2, gates=gates, use_dropout=use_dropout, training=self.training)\n",
    "        return (h_t, c_t)\n",
    "    \n",
    "    def forward(self, x, timesteps=None):\n",
    "        batch_size = x.size(0)\n",
    "        seq_len = x.size(1)\n",
    "        if timesteps is None:\n",
    "            time = 2*seq_len\n",
    "        \n",
    "        # initialize buffer\n",
    "        B = embedding(x)\n",
    "        s_b = torch.gt(x, 0).float()\n",
    "        \n",
    "        # initialize stack\n",
    "        V = [Variable(torch.zeros(batch_size, self.hidden_size))]\n",
    "        s = [Variable(torch.zeros(batch_size))]\n",
    "        controller_state = self.init_controller(batch_size)\n",
    "        \n",
    "        # LSTM controller timesteps\n",
    "        for t in range(time):\n",
    "            # Read from stack and buffer\n",
    "            x_b, _ = self.readBuffer(alpha=None, B=B, s_b=s_b, pop=False)\n",
    "            x_1, x_2, _ = self.readStack(alpha=None, V=V, s=s, pop=False)\n",
    "            x_t = torch.cat([x_b, x_1, x_2], 1)\n",
    "            \n",
    "            # Get alphas from controller\n",
    "            controller_state = self.controller(x_t, controller_state)\n",
    "            hidden_state = controller_state[0]\n",
    "            alphas = F.softmax(self.alpha_projector(hidden_state))\n",
    "            alpha_r = alphas[:, 0]\n",
    "            alpha_s = alphas[:, 1]\n",
    "            \n",
    "            # Read from stack, reduce (treelstm), and push onto stack\n",
    "            stack_reduce1, stack_reduce2, s = self.readStack(alpha_r, V, s, pop=True)\n",
    "            tree_state = self.run_tree(stack_reduce1, stack_reduce2)\n",
    "            hidden_state_tree = tree_state[0]\n",
    "            V, s = self.pushStack(vector=hidden_state_tree, alpha=alpha_r, V=V, s=s)\n",
    "            \n",
    "            # Shift from buffer and push onto stack\n",
    "            buffer_shift, s_b = self.readBuffer(alpha_s, B, s_b, pop=True)\n",
    "            V, s = self.pushStack(vector=buffer_shift, alpha=alpha_s, V=V, s=s)\n",
    "            \n",
    "        # Pop from top of stack with strength 1 as final sentence representation\n",
    "        x_1, x_2, _ = self.readStack(alpha=None, V=V, s=s, pop=False)\n",
    "        return x_1\n",
    "\n",
    "vocab_size = 50\n",
    "embedding_dim = 30\n",
    "batch_size = 3\n",
    "hidden_size = embedding_dim\n",
    "\n",
    "np_input = np.random.randint(low=1, high=vocab_size, size=(batch_size, sequence_length))\n",
    "np_input[1][-1] = 0\n",
    "np_input[2][-1] = 0\n",
    "np_input[2][-2] = 0\n",
    "\n",
    "inputs = Variable(torch.from_numpy(np_input))\n",
    "print(inputs)\n",
    "\n",
    "softstack = SoftStack(embedding_dim=embedding_dim, hidden_size=hidden_size, vocab_size=vocab_size)\n",
    "softstack(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
